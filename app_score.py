"""
Created on Thu Oct 17 2025
@author: trieukimlanh

üéì ·ª®ng d·ª•ng t√≠nh ƒëi·ªÉm CLO_30 (m√£ ƒë·ªÅ linh ho·∫°t)
"""

import re
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import unidecode

# ====================== GIAO DI·ªÜN ======================
st.set_page_config(page_title="·ª®ng d·ª•ng t√≠nh ƒëi·ªÉm CLO_30", layout="wide")
st.title("üéì ·ª®ng d·ª•ng t√≠nh ƒëi·ªÉm CLO_30")

st.sidebar.header("‚öôÔ∏è Upload d·ªØ li·ªáu")
uploaded_files = st.sidebar.file_uploader(
    "üìÇ T·∫£i l√™n c√°c file CSV (df1.csv, df2.csv, df3.csv, df4.csv)",
    type=["csv"],
    accept_multiple_files=True
)

# --- N√∫t x·ª≠ l√Ω ---
if st.sidebar.button("‚ñ∂Ô∏è Th·ª±c hi·ªán t√≠nh ƒëi·ªÉm"):
    if not uploaded_files:
        st.error("‚ö†Ô∏è Vui l√≤ng t·∫£i ƒë·ªß 4 file df1, df2, df3, df4 tr∆∞·ªõc khi ch·∫°y.")
        st.stop()

    # ======= 1. T·ª± nh·∫≠n d·∫°ng file =======
    df1_file = next((f for f in uploaded_files if "df1" in f.name.lower()), None)
    df2_file = next((f for f in uploaded_files if "df2" in f.name.lower()), None)
    df3_file = next((f for f in uploaded_files if "df3" in f.name.lower()), None)
    df4_file = next((f for f in uploaded_files if "df4" in f.name.lower()), None)

    if not all([df1_file, df2_file, df3_file, df4_file]):
        st.error("‚ö†Ô∏è Thi·∫øu file! C·∫ßn c√≥ ƒë·ªß df1.csv, df2.csv, df3.csv v√† df4.csv.")
        st.stop()

    try:
        # ======= 2. ƒê·ªçc d·ªØ li·ªáu =======
        df1 = pd.read_csv(df1_file)
        df2 = pd.read_csv(df2_file)
        df3 = pd.read_csv(df3_file)
        df4 = pd.read_csv(df4_file)

        # ======= 3. Chu·∫©n h√≥a & ph√°t hi·ªán c·ªôt =======
        # chu·∫©n h√≥a 'C√¢u' trong df3 ƒë·ªÉ kh·ªõp v·ªõi t√™n c·ªôt df2
        def normalize_question_name(s):
            s = str(s)
            s = unidecode.unidecode(s)
            s = s.strip().replace(' ', '').lower()
            s = re.sub(r'cau0+(\d+)', r'cau\1', s)   # cau01 -> cau1
            s = re.sub(r'[^a-z0-9]', '', s)         # lo·∫°i k√Ω t·ª± l·∫°
            return s

        df3['C√¢u'] = df3['C√¢u'].astype(str).apply(normalize_question_name)

        # T·ª± ph√°t hi·ªán c·ªôt "ƒë√°p √°n" trong df3 (c√°c c·ªôt ch·ª©a "ƒë√°p" ho·∫∑c "dap")
        ans_cols = [c for c in df3.columns if re.search(r'ƒë√°p|dap|dapan', c, re.IGNORECASE)]
        # C√°c c·ªôt m√£ ƒë·ªÅ l√† ph·∫ßn c√≤n l·∫°i (ngo·∫°i tr·ª´ 'C√¢u' v√† ans_cols)
        de_cols = [c for c in df3.columns if c not in ['C√¢u'] + ans_cols]
        if len(de_cols) == 0:
            st.error("Kh√¥ng t√¨m th·∫•y c·ªôt m√£ ƒë·ªÅ trong df3. Ki·ªÉm tra l·∫°i df3 (c·ªôt m√£ CLO/ƒë·ªÅ).")
            st.stop()

        # Chu·∫©n h√≥a n·ªôi dung c·ªôt m√£ ƒë·ªÅ (gi√° tr·ªã l√† m√£ CLO)
        for de in de_cols:
            df3[de] = df3[de].astype(str).str.strip().str.upper().replace({'NAN': '', 'nan': ''})

        # Chu·∫©n h√≥a c·ªôt ƒë√°p √°n (n·∫øu c√≥) -> uppercase, no-space
        for c in ans_cols:
            df3[c] = df3[c].astype(str).str.strip().str.upper()

        # ===== chu·∫©n h√≥a df4 (CLO -> ƒêi·ªÉm) =====
        df4['CLO'] = df4['CLO'].astype(str).str.strip().str.upper()
        df4['ƒêi·ªÉm'] = pd.to_numeric(df4['ƒêi·ªÉm'], errors='coerce').fillna(0)
        clo_point_map = df4.set_index('CLO')['ƒêi·ªÉm'].to_dict()

        # T·∫°o c·ªôt ƒêi·ªÉm_<de> trong df3 b·∫±ng map t·ª´ df4
        for de in de_cols:
            df3[f"ƒêi·ªÉm_{de}"] = df3[de].map(clo_point_map).fillna(0)

        # ===== chu·∫©n h√≥a df2 (t√™n c·ªôt v√† gi√° tr·ªã) =====
        def normalize_df2_col(s):
            s = str(s)
            s = unidecode.unidecode(s)
            s = s.strip().replace(' ', '').lower()
            s = re.sub(r'cau0+(\d+)', r'cau\1', s)
            s = re.sub(r'[^a-z0-9]', '', s)
            return s

        orig_df2_cols = list(df2.columns)
        df2_col_map = {c: normalize_df2_col(c) for c in orig_df2_cols}
        # rename temporarily
        df2.rename(columns=df2_col_map, inplace=True)

        # t√¨m c·ªôt ch·ª©a m√£ ƒë·ªÅ trong df2 (t√™n nh∆∞ 'de' ho·∫∑c 'ƒë·ªÅ' ho·∫∑c 'ma de')
        de_col_candidates = [c for c in df2.columns if re.search(r'\bde\b|\bd√™\b|ma?de|code', c, re.IGNORECASE)]
        if not de_col_candidates:
            # c·ªë fallback: c·ªôt c√≥ t√™n 'ƒë·ªÅ' sau b·ªè d·∫•u?
            possible = [c for c in df2.columns if 'de' == c or c.startswith('de')]
            de_col = possible[0] if possible else None
        else:
            de_col = de_col_candidates[0]

        if de_col is None:
            # th·ª≠ t√¨m c·ªôt c√≥ t√™n 'mssv' ƒë·ªÉ ch·∫Øc ch·∫Øn df2 structure
            st.error("Kh√¥ng t√¨m th·∫•y c·ªôt m√£ ƒë·ªÅ trong df2 (v√≠ d·ª• 'de' ho·∫∑c 'ƒë·ªÅ').")
            st.stop()

        # Chu·∫©n h√≥a t·∫•t c·∫£ gi√° tr·ªã c√¢u trong df2 th√†nh uppercase ch·ªØ c√°i (A/B/C/D)
        df2_cols_questions = [c for c in df2.columns if c.startswith('cau')]
        for c in df2_cols_questions:
            df2[c] = df2[c].astype(str).str.strip().str.upper()

        # ======= 4. T·∫°o mapping gi·ªØu 'C√¢u' (df3) v√† c·ªôt df2 =======
        df2_question_cols = df2_cols_questions
        df3_question_keys = df3['C√¢u'].unique().tolist()

        # build mapping cau_key -> df2_col (nhi·ªÅu chi·∫øn l∆∞·ª£c)
        cau_match_map = {}
        for k in df3_question_keys:
            # direct
            if k in df2_question_cols:
                cau_match_map[k] = k
                continue
            # try numeric suffix
            m = re.search(r'(\d+)$', k)
            mapped = None
            if m:
                num = m.group(1).lstrip('0')
                for c in df2_question_cols:
                    mc = re.search(r'(\d+)$', c)
                    if mc and mc.group(1).lstrip('0') == num:
                        mapped = c
                        break
            # fallback: try contains num
            if not mapped:
                for c in df2_question_cols:
                    if k in c or c in k:
                        mapped = c
                        break
            cau_match_map[k] = mapped

        unmatched = [k for k, v in cau_match_map.items() if v is None]
        if unmatched:
            st.warning(f"‚ö†Ô∏è M·ªôt s·ªë 'C√¢u' trong df3 kh√¥ng kh·ªõp v·ªõi c·ªôt c√¢u df2 v√† s·∫Ω b·ªã b·ªè qua: {unmatched[:10]}")

        # ======= 5. H√†m ch·∫•m ƒëi·ªÉm linh ho·∫°t (d√πng de_col) =======
        def calc_clo_scores(row):
            clo_scores = {}
            de_val = row.get(de_col, None)
            if pd.isna(de_val):
                return pd.Series(clo_scores)
            # chu·∫©n ho√° ki·ªÉu m√£ ƒë·ªÅ th√†nh chu·ªói gi·ªëng t√™n c·ªôt df3
            try:
                de_code = str(int(float(de_val)))  # 134.0 -> '134'
            except Exception:
                de_code = str(de_val).strip()
            # t√¨m t√™n c·ªôt ƒë√°p √°n trong df3 cho de_code: ∆∞u ti√™n exact 'ƒê√°p √°n_<de_code>' ho·∫∑c ch·ª©a de_code
            answer_col = None
            for ac in ans_cols:
                if re.search(re.escape(de_code), ac):
                    answer_col = ac
                    break
            if not answer_col:
                # try 'ƒê√°p √°n' without code if single answer column exists
                if len(ans_cols) == 1:
                    answer_col = ans_cols[0]

            if not answer_col:
                # kh√¥ng c√≥ c·ªôt ƒë√°p √°n cho ƒë·ªÅ n√†y ‚Äî b·ªè qua
                return pd.Series(clo_scores)

            de_col_in_df3 = None
            for cand in de_cols:
                if re.search(re.escape(str(cand)), str(cand)) and str(cand).strip():
                    # cand is itself; we just check membership of de_code in column name OR use columns as is
                    pass
            # choose the de column that corresponds to this de_code: usually column name equals de_code or contains it
            for cand in de_cols:
                if str(cand).strip() == de_code or re.search(re.escape(de_code), str(cand)):
                    de_col_in_df3 = cand
                    break
            if de_col_in_df3 is None:
                # fallback: if only one de_col in df3, use it
                if len(de_cols) == 1:
                    de_col_in_df3 = de_cols[0]
                else:
                    # try numeric match on column names
                    for cand in de_cols:
                        m = re.search(r'(\d+)', str(cand))
                        if m and m.group(1) == de_code:
                            de_col_in_df3 = cand
                            break
            if de_col_in_df3 is None:
                # kh√¥ng th·ªÉ x√°c ƒë·ªãnh c·ªôt m√£ ƒë·ªÅ trong df3 cho de n√†y
                return pd.Series(clo_scores)

            # build point column name
            point_col = f"ƒêi·ªÉm_{de_col_in_df3}" if f"ƒêi·ªÉm_{de_col_in_df3}" in df3.columns else None

            # iterate rows in df3 and compare
            for _, q in df3.iterrows():
                cau_key = q['C√¢u']
                df2_col = cau_match_map.get(cau_key)
                if not df2_col:
                    continue
                pa_sv = str(row.get(df2_col, '')).strip().upper()
                dap_an = str(q.get(answer_col, '')).strip().upper()
                clo_code = str(q.get(de_col_in_df3, '')).strip().upper()
                diem = float(q.get(point_col, 0)) if point_col else 0.0

                if dap_an and pa_sv == dap_an and clo_code:
                    clo_scores[clo_code] = clo_scores.get(clo_code, 0) + diem

            return pd.Series(clo_scores)

        # ======= 6. T√≠nh ƒëi·ªÉm cho to√†n b·ªô sinh vi√™n =======
        df_clo = df2.apply(calc_clo_scores, axis=1)
        # restore MSSV original column name in df2 to insert as MSSV
        # find original MSSV col (before rename we kept orig names)
        mssv_col = next((c for c in df2.columns if 'mssv' in c.lower()), None)
        if mssv_col is None:
            # try common names
            mssv_col = next((c for c in df2.columns if c in ['mssv','id','studentid']), None)
        if mssv_col is None:
            st.error("Kh√¥ng t√¨m th·∫•y c·ªôt MSSV trong df2.")
            st.stop()
        df_clo.insert(0, 'MSSV', df2[mssv_col])

        # ======= 7. G·ªôp v√†o df1 (lo·∫°i b·ªè c·ªôt CLO c≈© ƒë·ªÉ tr√°nh _x/_y) =======
        df1_clean = df1.loc[:, ~df1.columns.str.contains('CLO|Tong|T·ªïng', case=False, regex=True)].copy()
        df_final = pd.merge(df1_clean, df_clo, on='MSSV', how='left').fillna(0)

        # ======= 8. T√≠nh t·ªïng ƒëi·ªÉm t·ªïng h·ª£p =======
        clo_columns = [c for c in df_final.columns if re.search(r'clo', str(c), re.IGNORECASE)]
        df_final["T·ªïng ƒëi·ªÉm"] = df_final[clo_columns].sum(axis=1) if clo_columns else 0

        # ======= 9. T·ªïng h·ª£p theo CLO1..CLO5 (t·ª± ƒë·ªông) =======
        # ph√°t hi·ªán c√°c nh√≥m CLO ch√≠nh (CLO1, CLO2, ...)
        main_clo_names = sorted({re.search(r'(CLO\d+)', c, re.IGNORECASE).group(1).upper()
                                 for c in clo_columns
                                 if re.search(r'(CLO\d+)', c, re.IGNORECASE)} ) if clo_columns else []
        for mc in main_clo_names:
            df_final[mc] = df_final[[c for c in df_final.columns if mc in c]].sum(axis=1)

        # t·ªïng c√°c main CLO
        if main_clo_names:
            df_final["T·ªïng ƒëi·ªÉm (CLO t·ªïng)"] = df_final[main_clo_names].sum(axis=1)
        else:
            df_final["T·ªïng ƒëi·ªÉm (CLO t·ªïng)"] = df_final["T·ªïng ƒëi·ªÉm"]

        # ======= 10. Hi·ªÉn th·ªã & t·∫£i k·∫øt qu·∫£ =======
        st.success("‚úÖ T√≠nh ƒëi·ªÉm ho√†n t·∫•t!")
        st.subheader("üìä K·∫øt qu·∫£ t·ªïng h·ª£p ƒëi·ªÉm CLO")
        st.dataframe(df_final)

        csv_final = df_final.to_csv(index=False).encode('utf-8-sig')
        st.download_button("üíæ T·∫£i file k·∫øt qu·∫£ ƒë·∫ßy ƒë·ªß", csv_final, "ket_qua_tich_hop_full.csv", "text/csv")

        # ======= 11. Ph·ªï ƒëi·ªÉm =======
        st.subheader("üéØ Ph·ªï ƒëi·ªÉm sinh vi√™n (theo t·ªïng ƒëi·ªÉm CLO)")
        bins = [0, 5, 6, 7, 8, 9, 10]
        labels = ["D∆∞·ªõi 5", "T·ª´ 5 - <6", "T·ª´ 6 - <7", "T·ª´ 7 - <8", "T·ª´ 8 - <9", "T·ª´ 9 - 10"]

        df_final["Nh√≥m ƒëi·ªÉm"] = pd.cut(
            df_final["T·ªïng ƒëi·ªÉm (CLO t·ªïng)"], bins=bins, labels=labels,
            right=False, include_lowest=True
        )
        score_dist = df_final["Nh√≥m ƒëi·ªÉm"].value_counts().reindex(labels, fill_value=0)

        col1, col2 = st.columns(2)
        with col1:
            st.dataframe(score_dist.reset_index().rename(columns={'index': 'Kho·∫£ng ƒëi·ªÉm', 'Nh√≥m ƒëi·ªÉm': 'S·ªë SV'}))
        with col2:
            fig, ax = plt.subplots(figsize=(6, 4))
            ax.bar(score_dist.index, score_dist.values, edgecolor='black')
            ax.set_title("Ph·ªï ƒëi·ªÉm sinh vi√™n")
            ax.set_xlabel("Kho·∫£ng ƒëi·ªÉm")
            ax.set_ylabel("S·ªë sinh vi√™n")
            for i, v in enumerate(score_dist.values):
                ax.text(i, v + 0.2, str(v), ha='center')
            st.pyplot(fig)

        # ======= 12. Th√¥ng tin t·ªïng ƒëi·ªÉm t·ªëi ƒëa =======
        max_score = df3[[c for c in df3.columns if c.startswith("ƒêi·ªÉm_")]].sum().max() if any(c.startswith("ƒêi·ªÉm_") for c in df3.columns) else 0
        st.info(f"üîç T·ªïng ƒëi·ªÉm t·ªëi ƒëa (n·∫øu ƒë√∫ng h·∫øt): {max_score:.2f}")

    except Exception as e:
        st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu: {e}")
